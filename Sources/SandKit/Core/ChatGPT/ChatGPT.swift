//
//  Copyright © 2023 Dennis Müller and all collaborators
//
//  Permission is hereby granted, free of charge, to any person obtaining a copy
//  of this software and associated documentation files (the "Software"), to deal
//  in the Software without restriction, including without limitation the rights
//  to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
//  copies of the Software, and to permit persons to whom the Software is
//  furnished to do so, subject to the following conditions:
//
//  The above copyright notice and this permission notice shall be included in all
//  copies or substantial portions of the Software.
//
//  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
//  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
//  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
//  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
//  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
//  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
//  SOFTWARE.
//

import Foundation



/// A simple and easy to use wrapper around the ChatGPT API from OpenAI, with support for GPT 3.5 turbo as well as GPT 4 and its large context variant.
public class ChatGPT {

    private let client: APIClient
    private let apiKey: String
    private let apiClientRequestHandler: _APIClientRequestHandler

    private let defaultModel: ChatGPTModel
    
    private let api: APITYPE

    /// A variant of `ChatGPT` that streams all the answers.
    ///
    /// This exposes the exact same methods as before, but it returns an `AsyncThrowingStream` that yields individual tokens as soon as they are generated by GPT.
    public let streamedAnswer: StreamedAnswer

    /// A simple and easy to use wrapper around the ChatGPT API from OpenAI, with support for GPT 3.5 turbo as well as GPT 4 and its large context variant.
    ///
    /// - Parameter apiKey: The api key you can generate in your account page on OpenAI's website.
    /// - Parameter defaultModel: Sets the default model for all requests coming from this `ChatGPT` instance.
    /// - Parameter urlSessionConfiguration: An optional URL session configuration object.
    public init(
        apiKey: String,
        defaultModel: ChatGPTModel = .gpt3,
        api: APITYPE = .openai,
        urlSessionConfiguration: URLSessionConfiguration? = nil
    ) {
        self.apiKey = apiKey
        self.api = api
        self.apiClientRequestHandler = .init(apiKey: apiKey)
        self.defaultModel = defaultModel
        
        let path: String
        switch api {
        case .azure:
            path = AZURE_API.base
        case .openai:
            path = API.base
        }
        
        self.client = APIClient(baseURL: URL(string: path)) { [apiClientRequestHandler] configuration in
            configuration.delegate = apiClientRequestHandler
            if let urlSessionConfiguration {
                configuration.sessionConfiguration = urlSessionConfiguration
            }
        }
        self.streamedAnswer = .init(client: client, apiKey: apiKey, defaultModel: defaultModel)
    }

    /// Ask ChatGPT a single prompt without any special configuration.
    /// - Parameter userPrompt: The prompt to send
    /// - Parameter systemPrompt: an optional system prompt to give GPT instructions on how to answer.
    /// - Parameter model: The model that should be used.
    /// - Returns: The response as string.
    /// - Throws: A `GPTSwiftError` if the request fails or the server returns an unauthorized status code.
    public func ask(
        _ userPrompt: String,
        withSystemPrompt systemPrompt: String? = nil,
        withConfig config: PromptConfig,
        model: ChatGPTModel = .default
    ) async throws -> String {
        var messages: [ChatMessage] = []

        if let systemPrompt {
            messages.insert(.init(role: .system, content: systemPrompt), at: 0)
        }

        messages.append(.init(role: .user, content: userPrompt))

        let path: String
        switch api {
        case .azure:
            path = AZURE_API.v1ChatCompletion
        case .openai:
            path = API.v1ChatCompletion
        }
        
        let usingModel = model is DefaultChatGPTModel ? defaultModel : model
        
        
        switch api {
        case .azure:
            let request = Request<ChatResponse>(
                path: path,
                method: .post,
                query: [("api-version", "2023-05-15")],
                body: ChatRequestAzure(model: usingModel, messages: messages, config: config)
            )
            
            print("[ChatGPT] Azure asking with config.")

            let response = try await send(request: request)
            guard let answer = response.choices.first?.message.content else {
                throw GPTSwiftError.responseParsingFailed
            }

            return answer
        case .openai:
            let request = Request<ChatResponse>(
                path: path,
                method: .post,
                body: ChatRequest(model: usingModel, messages: messages, config: config)
            )
            
            print("[ChatGPT] asking with config.")

            let response = try await send(request: request)
            guard let answer = response.choices.first?.message.content else {
                throw GPTSwiftError.responseParsingFailed
            }

            return answer
            
        }
    }

    /// Ask ChatGPT something by sending multiple messages without any special configuration.
    /// - Parameter messages: The chat messages.
    /// - Parameter model: The model that should be used.
    /// - Returns: The response as string.
    /// - Throws: A `GPTSwiftError` if the request fails or the server returns an unauthorized status code.
    public func ask(
        messages: [ChatMessage],
        withConfig config: PromptConfig,
        model: ChatGPTModel = .default
    ) async throws -> String {
        let usingModel = model is DefaultChatGPTModel ? defaultModel : model
        
        let path: String
        switch api {
        case .azure:
            path = AZURE_API.v1ChatCompletion
            
            let request = Request<ChatResponse>(
                path: path,
                method: .post,
                query: [("api-version", "2023-05-15")],
                body: ChatRequestAzure(messages: messages)
            )
            print("[ChatGPT] (AZURE) asking with messages.")

            let response = try await send(request: request)
            guard let answer = response.choices.first?.message.content else {
                throw GPTSwiftError.responseParsingFailed
            }

            return answer
        case .openai:
            path = API.v1ChatCompletion
            
            let request = Request<ChatResponse>(
                path: path,
                method: .post,
                body: ChatRequest(model: usingModel, messages: messages)
            )
            print("[ChatGPT] (OPENAI) asking with messages.")

            let response = try await send(request: request)
            guard let answer = response.choices.first?.message.content else {
                throw GPTSwiftError.responseParsingFailed
            }

            return answer
        }
    }

    /// Ask ChatGPT something by providing a chat request object, giving you full control over the request's configuration.
    /// - Parameter request: The request.
    /// - Returns: The response.
    /// - Throws: A `GPTSwiftError` if the request fails or the server returns an unauthorized status code.
    public func ask(request: ChatRequest) async throws -> ChatResponse {
        let path: String
        switch api {
        case .azure:
            path = AZURE_API.v1ChatCompletion
        case .openai:
            path = API.v1ChatCompletion
        }
        
        let request = Request<ChatResponse>(
            path: path,
            method: .post,
            body: request
        )

        return try await send(request: request)
    }

    /// Turns a chat request into a curl prompt that you can paste into a terminal.
    ///
    /// This might be useful for debugging to experimenting.
    /// Taken from [Abhishek Maurya](https://gist.github.com/abhi21git/3dc611aab9e1cf5e5343ba4b58573596) and slightly adjusted.
    /// - Parameters:
    ///   - chatRequest: The request.
    ///   - pretty: An option to make the curl prompt pretty.
    ///   - formatOutput: An option that, if set, puts the response through `json_pp` to prettify the json object.
    /// - Returns: The curl prompt.
    public func curl(for chatRequest: ChatRequest, pretty: Bool = true, formatOutput: Bool = true) async throws -> String {
        let request = Request(path: API.v1ChatCompletion, method: .post, body: chatRequest)
        var urlRequest = try await client.makeURLRequest(for: request)
        _addHeaders(to: &urlRequest, apiKey: apiKey)
        return urlRequest.curl(pretty: pretty, formatOutput: formatOutput)
    }

    /// Sends the request, catches all errors and replaces them with a `GPTSwiftError`. If successful, it returns the response value.
    /// - Parameter request: The request to send.
    /// - Returns: The response object, already decoded.
    private func send<Response: Codable>(request: Request<Response>) async throws -> Response {
        do {
            return try await client.send(request).value
        } catch {
            throw _errorToGPTSwiftError(error)
        }
    }
}
